{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceramic-harvey",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-roots",
   "metadata": {},
   "source": [
    "Here is where we will keep up with all the packages we need throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nervous-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard # for visualizing our models\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-finder",
   "metadata": {},
   "source": [
    "# Let's first prepare the data set for use\n",
    "In it's current state, the pokemon images are not sorted by the classes which we want to predict for. All 809 images are in the same folder, and some are of different extensions ie. png vs jpg. This is rather unuseful for creating our model. We will sort them using the csv file which contains their types, by reading this into a pandas dataframe, then creating the folders for each type and moving the images into their corresponding folders all as jpgs. We will only be sorting and creating our model with Type1 in mind, since there are way too many instances when Type2 is null. Please note that this code expect your notebook to be in the same folder as the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "muslim-victim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grass', 'Fire', 'Water', 'Bug', 'Normal', 'Poison', 'Electric', 'Ground', 'Fairy', 'Fighting', 'Psychic', 'Rock', 'Ghost', 'Ice', 'Dragon', 'Dark', 'Steel', 'Flying']\n"
     ]
    }
   ],
   "source": [
    "poke_img_dir = 'data/images/images/'\n",
    "poke_csv = 'data/pokemon.csv'\n",
    "poke_df = pd.read_csv(poke_csv)\n",
    "del poke_df['Type2'] # remove Type2 since we will not be working with it\n",
    "poke_classes = poke_df.Type1.unique().tolist()\n",
    "print(poke_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-shannon",
   "metadata": {},
   "source": [
    "Now that we have our classes, we need to create a folder for each and iterate through each pokemon image, copying them into their corresponding folder and converting them to .jpgs simultaneously for uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dental-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grass pokemons copied into corresponding folder.\n",
      "Fire pokemons copied into corresponding folder.\n",
      "Water pokemons copied into corresponding folder.\n",
      "Bug pokemons copied into corresponding folder.\n",
      "Normal pokemons copied into corresponding folder.\n",
      "Poison pokemons copied into corresponding folder.\n",
      "Electric pokemons copied into corresponding folder.\n",
      "Ground pokemons copied into corresponding folder.\n",
      "Fairy pokemons copied into corresponding folder.\n",
      "Fighting pokemons copied into corresponding folder.\n",
      "Psychic pokemons copied into corresponding folder.\n",
      "Rock pokemons copied into corresponding folder.\n",
      "Ghost pokemons copied into corresponding folder.\n",
      "Ice pokemons copied into corresponding folder.\n",
      "Dragon pokemons copied into corresponding folder.\n",
      "Dark pokemons copied into corresponding folder.\n",
      "Steel pokemons copied into corresponding folder.\n",
      "Flying pokemons copied into corresponding folder.\n"
     ]
    }
   ],
   "source": [
    "for poke_class in poke_classes:\n",
    "    class_dir = poke_img_dir + poke_class\n",
    "    os.mkdir(class_dir)\n",
    "    pokes = poke_df.loc[poke_df['Type1'] == poke_class] # get all pokemon for the current class\n",
    "    pokes = pokes.Name # we just need the names from the series\n",
    "    for poke in pokes:\n",
    "        search_str = poke_img_dir + poke + '.*' # string input for glob to find poke img file\n",
    "        poke_img = glob.glob(search_str)\n",
    "        poke_img = str(poke_img[0]) # convert file in list from glob search to string\n",
    "        class_folder = poke_img_dir + poke_class + '/' + poke + '.jpg' # convert all to jpg for uniformity\n",
    "        shutil.copy(poke_img, class_folder) # copy the image into class folder\n",
    "    print(poke_class + ' pokemons copied into corresponding folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-oriental",
   "metadata": {},
   "source": [
    "Now our data is sorted and ready to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-offense",
   "metadata": {},
   "source": [
    "# Create training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "straight-rating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 656 images belonging to 18 classes.\n",
      "Found 153 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    validation_split = 0.2, rescale = 1.0/255 \n",
    "    # split specifies 80% will got to training set and 20% to validation set\n",
    ")\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    poke_img_dir,\n",
    "    target_size = (120, 120), \n",
    "    color_mode = 'rgba', # rgba accounts for transparency\n",
    "    classes = poke_classes,\n",
    "    class_mode = 'categorical', \n",
    "    batch_size = 20, \n",
    "    shuffle = True,\n",
    "    seed = 7, # random seed\n",
    "    subset = 'training'\n",
    ")\n",
    "validation_set = train_datagen.flow_from_directory(\n",
    "    poke_img_dir,\n",
    "    target_size = (120, 120), \n",
    "    color_mode = 'rgba',\n",
    "    classes = poke_classes,\n",
    "    class_mode = 'categorical', \n",
    "    batch_size = 20, \n",
    "    shuffle = True,\n",
    "    seed = 7, #\n",
    "    subset = 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-scoop",
   "metadata": {},
   "source": [
    "Next let's find the weights of each class to account for imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "integral-spokesman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Grass': 0, 'Fire': 1, 'Water': 2, 'Bug': 3, 'Normal': 4, 'Poison': 5, 'Electric': 6, 'Ground': 7, 'Fairy': 8, 'Fighting': 9, 'Psychic': 10, 'Rock': 11, 'Ghost': 12, 'Ice': 13, 'Dragon': 14, 'Dark': 15, 'Steel': 16, 'Flying': 17} \n",
      "\n",
      "{0: 0.5784832451499118, 1: 0.8475452196382429, 2: 0.3961352657004831, 3: 0.6283524904214559, 4: 0.43386243386243384, 5: 1.3015873015873016, 6: 1.1388888888888888, 7: 1.4017094017094016, 8: 2.4296296296296296, 9: 1.5185185185185186, 10: 0.8475452196382429, 11: 0.984984984984985, 12: 1.6565656565656566, 13: 1.9181286549707601, 14: 1.6565656565656566, 15: 1.5185185185185186, 16: 1.7354497354497354, 17: 12.148148148148149}\n"
     ]
    }
   ],
   "source": [
    "print(training_set.class_indices, '\\n')\n",
    "weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "     np.unique(training_set.classes),\n",
    "     training_set.classes\n",
    ")\n",
    "classes = np.unique(training_set.classes)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-press",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "organic-digest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PokemonModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 120, 120, 4)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 117, 117, 30)      1950      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 58, 58, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 55, 55, 60)        28860     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 27, 27, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 24, 24, 120)       115320    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 12, 12, 120)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_30  (None, 120)               0         \n",
      "=================================================================\n",
      "Total params: 146,130\n",
      "Trainable params: 146,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# inputs are going to be 120x120 images with 4 color channels (transparency)\n",
    "input_shape = (120, 120, 4)\n",
    "model_inputs = tf.keras.Input(shape = input_shape)\n",
    "\n",
    "# first 2d convolution layer\n",
    "c1 = tf.keras.layers.Conv2D(\n",
    "    filters = 30, # the number of features, low level\n",
    "    kernel_size = 4, # size of the sliding window 4x4\n",
    "    activation = 'relu' # activation function\n",
    ")(model_inputs)\n",
    "# first pooling layer\n",
    "p1 = tf.keras.layers.MaxPool2D(\n",
    "    pool_size = 2, # window size over which to take the maximum\n",
    "    strides = 2 # specifies how far pooling window moves for each pooling step\n",
    ")(c1)\n",
    "\n",
    "# second 2d convolution layer\n",
    "c2 = tf.keras.layers.Conv2D(\n",
    "    filters = 60, # mid level\n",
    "    kernel_size = 4,\n",
    "    activation = 'relu'\n",
    ")(p1)\n",
    "# second pooling layer\n",
    "p2 = tf.keras.layers.MaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 2\n",
    ")(c2)\n",
    "\n",
    "# third 2d convolution layer\n",
    "c3 = tf.keras.layers.Conv2D(\n",
    "    filters = 120, # high level\n",
    "    kernel_size = 4,\n",
    "    activation = 'relu'\n",
    ")(p2)\n",
    "# third pooling layer\n",
    "p3 = tf.keras.layers.MaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 2\n",
    ")(c3)\n",
    "\n",
    "model_outputs = tf.keras.layers.GlobalAveragePooling2D()(p3) #changed to p2\n",
    "\n",
    "poke_model = tf.keras.Model(\n",
    "    name = 'PokemonModel',\n",
    "    inputs = model_inputs,\n",
    "    outputs = model_outputs\n",
    ")\n",
    "poke_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-rover",
   "metadata": {},
   "source": [
    "# Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "removed-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PokemonClassifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 120, 120, 4)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 117, 117, 120)     7800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 58, 58, 120)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 55, 55, 120)       230520    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 27, 27, 120)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 24, 24, 120)       230520    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling (None, 12, 12, 120)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_28  (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 18)                2178      \n",
      "=================================================================\n",
      "Total params: 471,018\n",
      "Trainable params: 471,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_inputs = poke_model.input # same inputs as the model\n",
    "classifier_outputs = tf.keras.layers.Dense(\n",
    "    units = 18,  # 18 neurons for categorical classification\n",
    "    activation = 'sigmoid' # sigmoid function sigmoid(x) = 1 / (1 + exp(-x))\n",
    ")(poke_model.output)\n",
    "\n",
    "poke_classifier = tf.keras.Model(\n",
    "    name = 'PokemonClassifier',\n",
    "    inputs = classifier_inputs,\n",
    "    outputs = classifier_outputs\n",
    ")\n",
    "\n",
    "poke_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-desert",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-emission",
   "metadata": {},
   "source": [
    "Now we will begin testing our model. We'll use tensorboard to visualize how well it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "independent-smoke",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 51s 2s/step - loss: 1.8386 - accuracy: 0.3443 - val_loss: 2.9451 - val_accuracy: 0.1176\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 53s 2s/step - loss: 1.7046 - accuracy: 0.3437 - val_loss: 2.8540 - val_accuracy: 0.1830\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 40s 1s/step - loss: 1.6844 - accuracy: 0.3598 - val_loss: 2.9532 - val_accuracy: 0.1569\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 40s 1s/step - loss: 1.6001 - accuracy: 0.4008 - val_loss: 2.7972 - val_accuracy: 0.1634\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 43s 1s/step - loss: 1.5943 - accuracy: 0.4329 - val_loss: 2.9324 - val_accuracy: 0.1503\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 48s 1s/step - loss: 1.5171 - accuracy: 0.4387 - val_loss: 2.8816 - val_accuracy: 0.1503\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 47s 1s/step - loss: 1.4476 - accuracy: 0.4024 - val_loss: 2.9876 - val_accuracy: 0.1438\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 49s 1s/step - loss: 1.4023 - accuracy: 0.4995 - val_loss: 2.9497 - val_accuracy: 0.1438\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 47s 1s/step - loss: 1.3503 - accuracy: 0.4879 - val_loss: 2.8718 - val_accuracy: 0.1895\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 57s 2s/step - loss: 1.2717 - accuracy: 0.5415 - val_loss: 3.0342 - val_accuracy: 0.1699\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 57s 2s/step - loss: 1.2051 - accuracy: 0.4946 - val_loss: 3.0173 - val_accuracy: 0.1438\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 59s 2s/step - loss: 1.2299 - accuracy: 0.5004 - val_loss: 2.8685 - val_accuracy: 0.1830\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 57s 2s/step - loss: 1.0680 - accuracy: 0.6053 - val_loss: 2.9372 - val_accuracy: 0.1830\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 58s 2s/step - loss: 1.0584 - accuracy: 0.5686 - val_loss: 3.0393 - val_accuracy: 0.1634\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 41s 1s/step - loss: 1.0560 - accuracy: 0.5956 - val_loss: 2.9145 - val_accuracy: 0.1895\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.9337 - accuracy: 0.6003"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-c2ec96576fc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpoke_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history = poke_classifier.fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/schei/workspace/4380/mini_project_1/p1venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/schei/workspace/4380/mini_project_1/p1venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/schei/workspace/4380/mini_project_1/p1venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/schei/workspace/4380/mini_project_1/p1venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/mnt/c/Users/schei/workspace/4380/mini_project_1/p1venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/schei/workspace/4380/mini_project_1/p1venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/mnt/c/Users/schei/workspace/4380/mini_project_1/p1venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/schei/workspace/4380/mini_project_1/p1venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_name = 'Poke-Classifier-CNN-{}-all120'.format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(log_name))\n",
    "\n",
    "poke_classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = poke_classifier.fit(\n",
    "    training_set,\n",
    "    validation_data = validation_set,\n",
    "    epochs = 30,\n",
    "    class_weight = class_weights,\n",
    "    callbacks = [tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-module",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-pizza",
   "metadata": {},
   "source": [
    "Below is a scrapped version of how I first built my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pediatric-volleyball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 120, 120, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sample = training_set.next()\n",
    "image_sample[0].shape\n",
    "#training_set = []\n",
    "#for poke_class in poke_classes:\n",
    "    #class_dir = os.path.join(poke_img_dir, poke_class) # path to type folders\n",
    "    #class_num = poke_classes.index(poke_class) # arbitrary classification value from index in array\n",
    "    #for poke_img in os.listdir(class_dir):\n",
    "        #poke_img_array = cv2.imread(os.path.join(class_dir, poke_img), cv2.IMREAD_UNCHANGED) # unchanged includes the alpha channel which is transparency \n",
    "        #rs_poke_img_array = cv2.resize(poke_img_array, (img_size, img_size)) # resized to 75x75\n",
    "        #training_set.append([rs_poke_img_array, class_num])\n",
    "#random.shuffle(training_set)\n",
    "#for sample in training_set[:20]:\n",
    "    #print(sample[1])\n",
    "# shows the class number for the first 20 entries, the set appears shuffled\n",
    "# Now that the set is shuffled, we can generate the variables we will use as input into our CNN.\n",
    "X = [] # features set\n",
    "y = [] # labels\n",
    "for features, label in training_set:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "# for use with keras X and y must be converted to numpy arrays\n",
    "X = np.array(X)\n",
    "X= X.reshape(-1, img_size, img_size, 3) # -1 to specify any amount of features, 3 RGB values for color\n",
    "y = np.array(y)\n",
    "#In order to save time later when making slight adjustments to our model, we'll use pickle to save our data.\n",
    "pickle_o = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_o)\n",
    "pickle_o.close()\n",
    "\n",
    "pickle_o = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_o)\n",
    "pickle_o.close()\n",
    "# test to ensure pickle worked\n",
    "\n",
    "#Now that we've completed our pre-processing, we can start to build or convolutional nerual network. For more information on how a CNN functions, please see my report for this project.\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "max_pixel = 255.0\n",
    "X = X/max_pixel # normalize the pixel values to a range between 0 and 1 to speed up training\n",
    "\n",
    "#create sequential model and add layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:])) # 64 units, (3,3) windows size\n",
    "model.add(Activation(\"relu\")) # rectify linear\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3))) # 1: ignores the -1 we inputted into reshape\n",
    "model.add(Activation(\"relu\")) # rectify linear\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# flatten the data set to 1D from 2D for to add dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#before we begin training our model, we need to ensure it has the correct weighting for our classes\n",
    "labels, counts = np.unique(y, return_counts = True)\n",
    "lcs = np.asarray((labels, counts)).T # combine labels and counts into one array for iteration\n",
    "total = y.size # total of all counts from labels is the same as y.size\n",
    "weights = [] # the weights of the classes in the order in which they are in the labels array\n",
    "for lc in lcs:\n",
    "    label = lc[0]\n",
    "    count = lc[1]\n",
    "    weight = (1 / count) * (total)/2.0 # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "    weights.append(weight)\n",
    "class_weight = dict(zip(labels, weights)) # combine the labels and weights arrays into one dict\n",
    "print(class_weight)\n",
    "print(poke_classes)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "model.fit(X, y, epochs = 10, batch_size = 16, class_weight=class_weight, validation_split = 0.1) # best to have batch size somewhere in 20s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
